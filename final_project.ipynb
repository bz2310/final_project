{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bz2310/final_project/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a_F9tpUcJyz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount(\"drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUfIEfDgplAQ"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/drive/MyDrive/Colab Notebooks/final_project'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6LMwjFqeLOZ"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLGP9DdmcNRM"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "csv_path = 'jena_climate_2009_2016.csv'\n",
        "if not os.path.exists(csv_path):\n",
        "    uri = \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\"\n",
        "    zip_path = keras.utils.get_file(origin=uri, fname=\"jena_climate_2009_2016.csv.zip\")\n",
        "    zip_file = ZipFile(zip_path)\n",
        "    zip_file.extractall()\n",
        "    df = pd.read_csv(csv_path).set_index('Date Time')\n",
        "    df.index = pd.to_datetime(df.index, format='%d.%m.%Y %H:%M:%S')\n",
        "    df.to_csv(f\"{root_path}/jena_climate_2009_2016.csv\")\n",
        "\n",
        "csv_path = f\"{root_path}/jena_climate_2009_2016.csv\"\n",
        "df = pd.read_csv(csv_path, index_col=0)\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df[5::6] ## hourly predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Czu5rVEJePbV"
      },
      "outputs": [],
      "source": [
        "def show_raw_visualization(data):\n",
        "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple', 'tab:pink', 'tab:olive', 'tab:cyan']\n",
        "    fig, axes = plt.subplots(nrows=7, ncols=2, figsize=(15, 20), dpi=80, facecolor=\"w\", edgecolor=\"k\")\n",
        "    for i, col in enumerate(list(data.columns)):\n",
        "        ax = data[col].plot(\n",
        "            ax=axes[i // 2, i % 2],title=col,rot=25, color=colors[i%len(colors)])\n",
        "    plt.tight_layout()\n",
        "\n",
        "show_raw_visualization(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA6HuSY6DDgL"
      },
      "outputs": [],
      "source": [
        "## clean outliers from wind speed\n",
        "\n",
        "display(df.filter(regex='wv').describe())\n",
        "\n",
        "display(df.filter(regex='wv').sort_values(by='wv (m/s)').head(5))\n",
        "\n",
        "df['wv (m/s)']  = df['wv (m/s)'].replace(-9999.0, 0).values\n",
        "df['max. wv (m/s)']  = df['max. wv (m/s)'].replace(-9999.0, 0).values\n",
        "\n",
        "## create wind vector columns instead of direction and velocity\n",
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians.\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components.\n",
        "df['Wx'] = wv*np.cos(wd_rad)\n",
        "df['Wy'] = wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate the max wind x and y components.\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-HhB349SzDI"
      },
      "outputs": [],
      "source": [
        "## To give model knowledge of seasonality:\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "## timestamp in seconds\n",
        "timestamp_s = df.reset_index()['Date Time'].map(pd.Timestamp.timestamp)\n",
        "\n",
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df['day_sin'] = np.sin(timestamp_s * (2 * np.pi / day)).values\n",
        "df['day_cos'] = np.cos(timestamp_s * (2 * np.pi / day)).values\n",
        "df['year_sin'] = np.sin(timestamp_s * (2 * np.pi / year)).values\n",
        "df['year_cos'] = np.cos(timestamp_s * (2 * np.pi / year)).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HevMXjBOVM4Q"
      },
      "outputs": [],
      "source": [
        "df.filter(regex='day_').head(72).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmSEYNwDe73P"
      },
      "outputs": [],
      "source": [
        "def show_heatmap(data):\n",
        "    import matplotlib as mp\n",
        "    plt.matshow(data.corr(), cmap='RdYlGn')\n",
        "    plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=90)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.yticks(range(data.shape[1]), data.columns, fontsize=14)\n",
        "\n",
        "    cb = plt.colorbar(mp.cm.ScalarMappable(cmap='RdYlGn'))\n",
        "    cb.ax.tick_params(labelsize=14)\n",
        "    plt.title(\"Feature Correlation Heatmap\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "show_heatmap(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcAprRsFe9PP"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqAE3I0YCzES"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkdRlsH_C0xQ"
      },
      "outputs": [],
      "source": [
        "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "\n",
        "## we are using 70% for training, 20% for validation, and 10% for test\n",
        "train_amt=0.7\n",
        "val_amt=0.2\n",
        "n = len(df)\n",
        "train_df = df[0:int(n*train_amt)]\n",
        "val_df = df[int(n*train_amt):int(n*(train_amt + val_amt))]\n",
        "test_df = df[int(n*train_amt+val_amt):]\n",
        "\n",
        "num_features = df.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA27rZ-KFiDQ"
      },
      "outputs": [],
      "source": [
        "## we use just train mean and train std instead of rolling normalization\n",
        "## we normalize data to take out means and variances\n",
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRBwlMTbBWCd"
      },
      "outputs": [],
      "source": [
        "display(train_df.describe().round(2))\n",
        "\n",
        "display(train_df.kurtosis().to_frame().round(2).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUY-B1ip2ond"
      },
      "outputs": [],
      "source": [
        "def gen_train_val_test(df, train_amt, val_amt):\n",
        "  column_indices = {name: i for i, name in enumerate(df.columns)}\n",
        "  n = len(df)\n",
        "  train_df = df[0:int(n*train_amt)]\n",
        "  val_df = df[int(n*train_amt):int(n*(train_amt + val_amt))]\n",
        "  test_df = df[int(n*train_amt+val_amt):]\n",
        "\n",
        "  train_mean = train_df.mean()\n",
        "  train_std = train_df.std()\n",
        "\n",
        "  train_df = (train_df - train_mean) / train_std\n",
        "  val_df = (val_df - train_mean) / train_std\n",
        "  test_df = (test_df - train_mean) / train_std\n",
        "  \n",
        "  return train_df, val_df, test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-6gojBUWnwh"
      },
      "source": [
        "# Data Windowing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXdViV3dF_M-"
      },
      "outputs": [],
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift, batch_size,\n",
        "               train_df, val_df, test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])\n",
        "    \n",
        "  def split_window(self, features):\n",
        "    inputs = features[:, self.input_slice, :]\n",
        "    labels = features[:, self.labels_slice, :]\n",
        "    if self.label_columns is not None:\n",
        "      labels = tf.stack(\n",
        "          [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "          axis=-1)\n",
        "\n",
        "    # Slicing doesn't preserve static shape information, so set the shapes\n",
        "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "    inputs.set_shape([None, self.input_width, None])\n",
        "    labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "  def make_dataset(self, data):\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    ds = keras.preprocessing.timeseries_dataset_from_array(\n",
        "        data=data,\n",
        "        targets=None,\n",
        "        sequence_length=self.total_window_size,\n",
        "        sequence_stride=1,\n",
        "        shuffle=True,\n",
        "        batch_size=self.batch_size)\n",
        "\n",
        "    ds = ds.map(self.split_window)\n",
        "\n",
        "    return ds\n",
        "\n",
        "  @property\n",
        "  def train(self):\n",
        "    return self.make_dataset(self.train_df)\n",
        "\n",
        "  @property\n",
        "  def validation(self):\n",
        "    return self.make_dataset(self.val_df)\n",
        "\n",
        "  @property\n",
        "  def test(self):\n",
        "    return self.make_dataset(self.test_df)\n",
        "\n",
        "  @property\n",
        "  def example(self):\n",
        "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "    result = getattr(self, '_example', None)\n",
        "    if result is None:\n",
        "      # No example batch was found, so get one from the `.train` dataset\n",
        "      result = next(iter(self.train))\n",
        "      # And cache it for next time\n",
        "      self._example = result\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WCPapg3BPti"
      },
      "outputs": [],
      "source": [
        "def gen_windows(train_df, val_df, test_df, verbose=False, batch_size=32):\n",
        "  ## using past 24 hours to predict next hour\n",
        "  ts_window = WindowGenerator(input_width=24, label_width=1, shift=1,batch_size=batch_size, \n",
        "                              train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "                              label_columns=['T (degC)'])\n",
        "\n",
        "  print(ts_window)\n",
        "\n",
        "  if verbose:\n",
        "    for example_inputs, example_labels in ts_window.train.take(1):\n",
        "      print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "      print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
        "\n",
        "  ## using past 24 hours to predict 24 hours later\n",
        "  tsshift_window = WindowGenerator(input_width=24, label_width=1, shift=24,batch_size=batch_size, \n",
        "                                   train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "                                    label_columns=['T (degC)'])\n",
        "\n",
        "  print(tsshift_window)\n",
        "\n",
        "  if verbose:\n",
        "    for example_inputs, example_labels in tsshift_window.train.take(1):\n",
        "      print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "      print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
        "\n",
        "  ## using past 24 hours to predict 24 hours later\n",
        "  tsblock_window = WindowGenerator(input_width=24, label_width=24, shift=24,batch_size=batch_size, \n",
        "                                   train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "                                  label_columns=['T (degC)'])\n",
        "\n",
        "  print(tsblock_window)\n",
        "\n",
        "  if verbose:\n",
        "    for example_inputs, example_labels in tsblock_window.train.take(1):\n",
        "      print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
        "      print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
        "\n",
        "  return (ts_window, tsshift_window, tsblock_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbJgkdpG3u8T"
      },
      "outputs": [],
      "source": [
        "train_df, val_df, test_df = gen_train_val_test(df, 0.7, 0.2)\n",
        "ts_window, tsshift_window, tsblock_window = gen_windows(train_df, val_df, test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjf94xtxGJTV"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iU5oyyBGK83"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from time import time\n",
        "class TimeHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time() - self.epoch_time_start)\n",
        "\n",
        "def compile_and_fit(model, window, checkpoint_name,\n",
        "                    epochs=10, learning_rate = 0.001, verbose=1\n",
        "                    ):\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
        "\n",
        "  checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "      monitor=\"val_loss\",\n",
        "      filepath=checkpoint_name,\n",
        "      verbose=1,\n",
        "      save_weights_only=True,\n",
        "      save_best_only=True,\n",
        "  )\n",
        "\n",
        "  timingcb = TimeHistory()\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
        "\n",
        "  history = model.fit(\n",
        "      window.train,\n",
        "      epochs=epochs,\n",
        "      validation_data=window.validation,\n",
        "      callbacks=[early_stopping, checkpoint, timingcb],\n",
        "      verbose=verbose\n",
        "  )\n",
        "\n",
        "  pd.DataFrame(timingcb.times).to_csv(checkpoint_name.replace(\".h5\", \"_timingcb.csv\"))\n",
        "\n",
        "  model.save(checkpoint_name)\n",
        "\n",
        "  history.history['test_eval'] = model.evaluate(window.test)\n",
        "  pickle.dump(history.history, open(checkpoint_name.replace(\".h5\", \".pickle\"), 'wb'))\n",
        "\n",
        "  return(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQUxxRmZlm82"
      },
      "outputs": [],
      "source": [
        "## input ignores batch size\n",
        "def lstm_model(lstm_size, input_shape):\n",
        "  inputs = keras.layers.Input(shape=input_shape)\n",
        "  lstm_out = keras.layers.LSTM(lstm_size)(inputs)\n",
        "  outputs = keras.layers.Dense(1)(lstm_out)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOSoTWS3-ysB"
      },
      "outputs": [],
      "source": [
        "def sequential_model(num_layers, l2, dropout, input_shape):\n",
        "  layers_list = [keras.layers.Flatten(input_shape=input_shape)]\n",
        "  for layer in range(0, num_layers):\n",
        "    if l2:\n",
        "      layers_list.append(keras.layers.Dense(32, activation='relu', \n",
        "        kernel_regularizer=keras.regularizers.l2(1e-4)))\n",
        "    else:\n",
        "      layers_list.append(keras.layers.Dense(32, activation='relu'))\n",
        "    if dropout:\n",
        "      layers_list.append(keras.layers.Dropout(rate=0.2))\n",
        "    layers_list.append(keras.layers.BatchNormalization(),)\n",
        "    \n",
        "  layers_list.append(keras.layers.Dense(1))\n",
        "  model = keras.models.Sequential(layers_list)\n",
        "  model.build()\n",
        "\n",
        "  return(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TFNPvCbD2p6"
      },
      "source": [
        "## Sequential Model Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-vRw8pi-U8o"
      },
      "outputs": [],
      "source": [
        "batch_size=128\n",
        "train_df, val_df, test_df = gen_train_val_test(df, 0.7, 0.2)\n",
        "ts_window, tsshift_window, tsblock_window = gen_windows(train_df, val_df, test_df, batch_size=batch_size)\n",
        "\n",
        "windows_dict = {\n",
        "                'tsshift': tsshift_window,\n",
        "                'tsblock': tsblock_window,\n",
        "                'ts': ts_window,\n",
        "                }\n",
        "\n",
        "for window_name, window in windows_dict.items():\n",
        "  for layers in [1, 2, 3, 4, 5]:\n",
        "    for l2 in [True, False]:\n",
        "      for dropout in [True, False]:\n",
        "        filename = f'{root_path}/model.seq_window.{window_name}_batchsize.{batch_size}_layers.{layers}_l2.{l2}_dropout.{dropout}.h5'\n",
        "        if os.path.exists(filename):\n",
        "          print(\"%s exists\"%filename)\n",
        "          #continue\n",
        "        model = sequential_model(2, l2=True, dropout=True, input_shape=window.example[0].shape[1:])\n",
        "        #print('Input shape:', window.example[0].shape)\n",
        "        #print('Output shape:', model(window.example[0]).shape)\n",
        "        history = compile_and_fit(model, window, f'{root_path}/model.seq_window.{window_name}_batchsize.{batch_size}_layers.{layers}_l2.{l2}_dropout.{dropout}.h5', epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Model Experiments with Feature Selection"
      ],
      "metadata": {
        "id": "330sAj1K1eWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = []\n",
        "output = []\n",
        "for batch in ts_window.train.take(20000):\n",
        "  x,y = batch\n",
        "  input.extend(np.asarray([y[0] for y in x.numpy()]))\n",
        "  output.extend([x[0][0] for x in y.numpy()])\n",
        "input = np.asarray(input)\n",
        "output = np.asarray(output)"
      ],
      "metadata": {
        "id": "YtwWcdco1tL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "linear = sm.OLS(output, input).fit_regularized(alpha=0.2, L1_wt=0.5)\n",
        "pd.DataFrame(linear.params, index = train_df.columns, columns = ['coef']).T.round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "KWKjrMfj1vLH",
        "outputId": "c87058f0-cd24-45ec-ca82-1908d7e0ace3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p (mbar)</th>\n",
              "      <th>T (degC)</th>\n",
              "      <th>Tpot (K)</th>\n",
              "      <th>Tdew (degC)</th>\n",
              "      <th>rh (%)</th>\n",
              "      <th>VPmax (mbar)</th>\n",
              "      <th>VPact (mbar)</th>\n",
              "      <th>VPdef (mbar)</th>\n",
              "      <th>sh (g/kg)</th>\n",
              "      <th>H2OC (mmol/mol)</th>\n",
              "      <th>rho (g/m**3)</th>\n",
              "      <th>Wx</th>\n",
              "      <th>Wy</th>\n",
              "      <th>max Wx</th>\n",
              "      <th>max Wy</th>\n",
              "      <th>day_sin</th>\n",
              "      <th>day_cos</th>\n",
              "      <th>year_sin</th>\n",
              "      <th>year_cos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>coef</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      p (mbar)  T (degC)  Tpot (K)  ...  day_cos  year_sin  year_cos\n",
              "coef       0.0      0.29      0.23  ...      0.0       0.0     -0.13\n",
              "\n",
              "[1 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "train_df, val_df, test_df = gen_train_val_test(df[['T (degC)', 'Tpot (K)', 'Tdew (degC)', 'VPmax (mbar)', 'year_cos']], 0.7, 0.2)\n",
        "ts_window, tsshift_window, tsblock_window = gen_windows(train_df, val_df, test_df, batch_size=batch_size)\n",
        "\n",
        "windows_dict = {\n",
        "                'tsshift': tsshift_window,\n",
        "                'tsblock': tsblock_window,\n",
        "                'ts': ts_window,\n",
        "                }\n",
        "\n",
        "for window_name, window in windows_dict.items():\n",
        "  for layers in [1, 2, 3, 4, 5]:\n",
        "    for l2 in [True, False]:\n",
        "      for dropout in [True, False]:\n",
        "        filename = f'{root_path}/model.seq_window.{window_name}_batchsize.{batch_size}_layers.{layers}_l2.{l2}_dropout.{dropout}.h5'\n",
        "        if os.path.exists(filename):\n",
        "          print(\"%s exists\"%filename)\n",
        "          continue\n",
        "        model = sequential_model(2, l2=True, dropout=True, input_shape=window.example[0].shape[1:])\n",
        "        #print('Input shape:', window.example[0].shape)\n",
        "        #print('Output shape:', model(window.example[0]).shape)\n",
        "        history = compile_and_fit(model, window, f'{root_path}/model.seqfeatureselected_window.{window_name}_batchsize.{batch_size}_layers.{layers}_l2.{l2}_dropout.{dropout}.h5', epochs=100)"
      ],
      "metadata": {
        "id": "TEd5HlxK2j1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZhQaJAvxgq5"
      },
      "source": [
        "## LSTM Model Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAKPdHkixjtP"
      },
      "outputs": [],
      "source": [
        "batch_size=128\n",
        "train_df, val_df, test_df = gen_train_val_test(df, 0.7, 0.2)\n",
        "ts_window, tsshift_window, tsblock_window = gen_windows(train_df, val_df, test_df, batch_size=batch_size)\n",
        "\n",
        "\n",
        "windows_dict = {\n",
        "                'tsshift': tsshift_window,\n",
        "                'tsblock': tsblock_window,\n",
        "                'ts': ts_window,\n",
        "                }\n",
        "\n",
        "for window_name, window in windows_dict.items():\n",
        "  for lstm_size in range(3, 10):\n",
        "        lstm_size = 2**lstm_size\n",
        "\n",
        "        filename = f'{root_path}/model.lstm_window.{window_name}_batchsize.{batch_size}_lstmsize.{lstm_size}.h5'\n",
        "        if os.path.exists(filename):\n",
        "          print(\"%s exists\"%filename)\n",
        "          continue\n",
        "        model = lstm_model(lstm_size, input_shape=window.example[0].shape[1:])\n",
        "        #print('Input shape:', window.example[0].shape)\n",
        "        #print('Output shape:', model(window.example[0]).shape)\n",
        "        history = compile_and_fit(model, window, filename, epochs=100, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkBCYo2Sxbas"
      },
      "source": [
        "## Test Post Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWBN866npl_-"
      },
      "outputs": [],
      "source": [
        "filename = '/content/drive/MyDrive/Colab Notebooks/final_project/model.seq_window.ts_batchsize.32_layers.3_l2.True_dropout.False.h5'\n",
        "\n",
        "import pickle\n",
        "history = pickle.load(open(filename.replace(\".h5\", \".pickle\"), 'rb'))\n",
        "history['test_eval']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnw1XI4-pw3y"
      },
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "train_df, val_df, test_df = gen_train_val_test(df, 0.7, 0.2)\n",
        "ts_window, tsshift_window, tsblock_window = gen_windows(train_df, val_df, test_df, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPyG8dNBqW82"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uiAsZc_qjxw"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(ts_window.test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VieeptN7wJDB"
      },
      "outputs": [],
      "source": [
        "for x,y in tsshift_window.test.take(1):\n",
        "  print(x.shape)\n",
        "  print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-asz09ghvKik"
      },
      "outputs": [],
      "source": [
        "for i in range(2,7):\n",
        "  plt.plot(x[i].numpy().T[1])\n",
        "  plt.plot(24, y[i], marker='+')\n",
        "  plt.plot(24, predictions[i], marker='o')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFWAq37x5Fgy"
      },
      "source": [
        "# Post-Experiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6X0MFZ0GGOL-"
      },
      "outputs": [],
      "source": [
        "def visualize_loss(history, title):\n",
        "    loss = history[\"loss\"]\n",
        "    val_loss = history[\"val_loss\"]\n",
        "    epochs = range(len(val_loss))\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
        "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_loss(history, \"Training and Validation Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCGCoInap5xe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "final_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdl0NQlPLznwZ5F/becmwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}